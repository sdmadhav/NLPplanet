{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a96783a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\2019c\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\gutenberg.zip.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('gutenberg')\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f7ca019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list all of the corpora from project Gutenberg in NLTK\n",
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f41455a",
   "metadata": {},
   "source": [
    "As we can see, the gutenberg module allows easy access to a subset of all the books available on the website. In this example, weâ€™ll focus on shakespeare-caesar, shakespeare-hamlet, and shakespeare-macbeth. The plays come as .txt files, they can be read with the nltk.corpus.gutenberg.words function which returns them already tokenized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3994d4c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0077c433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakespeare_corpora = [i for i in nltk.corpus.gutenberg.fileids() if i.startswith('shakespeare')]\n",
    "shakespeare_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f847cf37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[ The Tragedie of Julius Caesar by William Shakespeare 1599 ] Actus Primus . Scoena Prima . Enter Flauius , Murellus , and certaine Commoners ouer the Stage . Flauius . Hence : home you idle Creatures , get you home : Is this a Holiday ? What , know you not ( Being Mechanicall ) you ought not walke Vpon a labouring day , without the signe Of your Profession ? Speake , what Trade art thou ? Car . Why Sir , a Carpenter Mur . Where is thy Leather Apron , and thy Rule ? What dost'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all the corpora\n",
    "corpora = {\n",
    "    corpus_name: nltk.corpus.gutenberg.words(corpus_name)\n",
    "    for corpus_name in shakespeare_corpora\n",
    "}\n",
    "\n",
    "# print some sentences from a corpus\n",
    "words = corpora[shakespeare_corpora[0]][:100]\n",
    "\" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53bdd62b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([['[', 'The', 'Tragedie', 'of', 'Julius', 'Caesar', ...], ['[', 'The', 'Tragedie', 'of', 'Hamlet', 'by', ...], ['[', 'The', 'Tragedie', 'of', 'Macbeth', 'by', ...]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpora.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9cb5e37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count how many times a specific token is right after another token in a corpora\n",
    "\n",
    "# example = {\n",
    "#     'the': {'king': 10, 'queen': 5,},\n",
    "#     'a': {'king': 2, 'queen': 8,}\n",
    "# }\n",
    "\n",
    "counts = {}\n",
    "for corpus in corpora.values():\n",
    "    for i in range(len(corpus)-1):\n",
    "        token = corpus[i].lower()\n",
    "        next_token = corpus[i+1].lower()\n",
    "        if token not in counts:\n",
    "            counts[token] = {}\n",
    "        if next_token not in counts[token]:\n",
    "            counts[token][next_token] = 0\n",
    "        counts[token][next_token] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23687b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 37),\n",
       " ('caesars', 1),\n",
       " ('your', 5),\n",
       " ('their', 3),\n",
       " ('brutus', 1),\n",
       " ('that', 2),\n",
       " ('seuerall', 1),\n",
       " ('qualitie', 1),\n",
       " ('bondage', 1),\n",
       " ('power', 1)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(counts['from'].items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b22bbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so here we can see that the token \"from\" is followed by \"the\" token 37 times and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "afd0073e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in counts:\n",
    "    total_count = sum(counts[token].values())\n",
    "    for next_token in counts[token]:\n",
    "        counts[token][next_token] /= total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1cba22c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 0.19170984455958548),\n",
       " ('his', 0.06217616580310881),\n",
       " ('her', 0.05181347150259067),\n",
       " ('my', 0.046632124352331605),\n",
       " ('this', 0.046632124352331605),\n",
       " ('our', 0.04145077720207254),\n",
       " ('me', 0.04145077720207254),\n",
       " ('a', 0.031088082901554404),\n",
       " ('your', 0.025906735751295335),\n",
       " ('him', 0.025906735751295335)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print 10 examples of \"from\" token and their next token probabilities \n",
    "probs_From= list(counts[\"from\"].items())\n",
    "probs_From.sort(key=lambda x: x[1], reverse=True)\n",
    "probs_From[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6219fa63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dd1d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we need to create a function that will generate text based on the probabilities we have calculated above.\n",
    "def generate_text(start_token, length=20):\n",
    "    current_token = start_token.lower()\n",
    "    output = [current_token]\n",
    "    for _ in range(length-1):\n",
    "        if current_token not in counts:\n",
    "            break\n",
    "        next_tokens = list(counts[current_token].keys())\n",
    "        next_probs = list(counts[current_token].values())\n",
    "        # np.random.seed(42) # this will produce the same output every time \n",
    "        current_token = np.random.choice(next_tokens, size=1, p=next_probs)[0]\n",
    "        output.append(current_token)\n",
    "    return \" \".join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "96d458a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from a souldier , to his brutus . and you cask . and you cask . and you cask . and you cask . and you cask . and you cask . and you cask . and you cask . and you cask . and you cask . and you cask . and you cask . and you cask . and you cask . and you cask . and you cask . and you cask . and you cask . and you cask . and you cask . and you cask . and you cask . and you cask . and you cask . and you cask . and you cask . and you cask . and you cask . and you cask . and you cask . and you cask . and you cask . and you cask . and you cask . and you cask . and you'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets generate some text\n",
    "generate_text(\"from\", length=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18392a8",
   "metadata": {},
   "source": [
    "# Drwaback of the N-gram for text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d08035c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_corpus = nltk.corpus.gutenberg.words('shakespeare-hamlet.txt') + nltk.corpus.gutenberg.words('shakespeare-macbeth.txt') + nltk.corpus.gutenberg.words('shakespeare-caesar.txt')\n",
    "lowered_corpus = [i.lower() for i in whole_corpus]\n",
    "whole_string = \" \".join(lowered_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2a035009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_string.count(\"from \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b79e22d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_string.count(\"from the \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "53c51638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_string.count(\"from the streets \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285321da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpplanet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
