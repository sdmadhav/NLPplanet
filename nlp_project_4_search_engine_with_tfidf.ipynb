{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab21c6e9",
   "metadata": {},
   "source": [
    "# Libraries\n",
    "Let's import the libraries we will need in this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31eedcbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\2019c\\OneDrive\\Desktop\\NLPplanet\\nlpplanet\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aac9e72",
   "metadata": {},
   "source": [
    "# Download the dataset\n",
    "We can now download the dataset of Medium articles from the HuggingFace Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d3454f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download the dataset of medium articles from the HuggingFace Hub\n",
    "\n",
    "df_articles = pd.read_csv(\n",
    "    hf_hub_download('fabiochiu/medium-articles', repo_type='dataset', filename='medium_articles.csv'\n",
    "                    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98cf4e8",
   "metadata": {},
   "source": [
    "There are 192,368 articles in total, but let's sample 10000 of them to make computations faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7a3d3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_articles = df_articles.sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a06e77f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "      <th>authors</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60716</th>\n",
       "      <td>We Mapped How the Coronavirus Is Driving New S...</td>\n",
       "      <td>As of March 25, the Ministry of Health had bui...</td>\n",
       "      <td>https://onezero.medium.com/the-pandemic-is-a-t...</td>\n",
       "      <td>['Dave Gershgorn']</td>\n",
       "      <td>2020-05-22 15:10:30.160000+00:00</td>\n",
       "      <td>['Privacy', 'Coronavirus', 'Surveillance', 'Fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75637</th>\n",
       "      <td>My day with her ________________ At the early ...</td>\n",
       "      <td>My day with her\\n\\n________________\\n\\nAt the ...</td>\n",
       "      <td>https://medium.com/@sheriffdeenbnhamzah1999/my...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2020-12-24 06:04:27.124000+00:00</td>\n",
       "      <td>['Story']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55104</th>\n",
       "      <td>Cross-border arbitrage strategies</td>\n",
       "      <td>This time we continue our series of articles w...</td>\n",
       "      <td>https://medium.com/hyperquant/cross-border-arb...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2018-10-17 16:47:27.788000+00:00</td>\n",
       "      <td>['Algorithmic Trading', 'Bitcoin', 'Cryptocurr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120691</th>\n",
       "      <td>Latest Youth STEM Competition 最新青少年科技竞赛信息 (11/22)</td>\n",
       "      <td>有关青少年的最新科技竞赛信息 （K-12)，每周更新\\n\\n最新更新 2020年11月22日...</td>\n",
       "      <td>https://medium.com/@youthinnolab/latest-youth-...</td>\n",
       "      <td>['Youth Innovation Lab']</td>\n",
       "      <td>2020-11-23 04:44:38.491000+00:00</td>\n",
       "      <td>['STEM', 'Coding', 'Youth', 'Competition']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157713</th>\n",
       "      <td>5 Best Food Places In Italy | Viaggi Finti</td>\n",
       "      <td>Does eating brings you pleasure? Food is not o...</td>\n",
       "      <td>https://medium.com/@viaggifintishedirpharma/5-...</td>\n",
       "      <td>['Viaggi Finti Shedir Pharma']</td>\n",
       "      <td>2020-05-20 18:33:52.483000+00:00</td>\n",
       "      <td>['Viaggi Finti', 'Viaggi Finti Shedirpharma', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title  \\\n",
       "60716   We Mapped How the Coronavirus Is Driving New S...   \n",
       "75637   My day with her ________________ At the early ...   \n",
       "55104                   Cross-border arbitrage strategies   \n",
       "120691  Latest Youth STEM Competition 最新青少年科技竞赛信息 (11/22)   \n",
       "157713         5 Best Food Places In Italy | Viaggi Finti   \n",
       "\n",
       "                                                     text  \\\n",
       "60716   As of March 25, the Ministry of Health had bui...   \n",
       "75637   My day with her\\n\\n________________\\n\\nAt the ...   \n",
       "55104   This time we continue our series of articles w...   \n",
       "120691  有关青少年的最新科技竞赛信息 （K-12)，每周更新\\n\\n最新更新 2020年11月22日...   \n",
       "157713  Does eating brings you pleasure? Food is not o...   \n",
       "\n",
       "                                                      url  \\\n",
       "60716   https://onezero.medium.com/the-pandemic-is-a-t...   \n",
       "75637   https://medium.com/@sheriffdeenbnhamzah1999/my...   \n",
       "55104   https://medium.com/hyperquant/cross-border-arb...   \n",
       "120691  https://medium.com/@youthinnolab/latest-youth-...   \n",
       "157713  https://medium.com/@viaggifintishedirpharma/5-...   \n",
       "\n",
       "                               authors                         timestamp  \\\n",
       "60716               ['Dave Gershgorn']  2020-05-22 15:10:30.160000+00:00   \n",
       "75637                               []  2020-12-24 06:04:27.124000+00:00   \n",
       "55104                               []  2018-10-17 16:47:27.788000+00:00   \n",
       "120691        ['Youth Innovation Lab']  2020-11-23 04:44:38.491000+00:00   \n",
       "157713  ['Viaggi Finti Shedir Pharma']  2020-05-20 18:33:52.483000+00:00   \n",
       "\n",
       "                                                     tags  \n",
       "60716   ['Privacy', 'Coronavirus', 'Surveillance', 'Fa...  \n",
       "75637                                           ['Story']  \n",
       "55104   ['Algorithmic Trading', 'Bitcoin', 'Cryptocurr...  \n",
       "120691         ['STEM', 'Coding', 'Youth', 'Competition']  \n",
       "157713  ['Viaggi Finti', 'Viaggi Finti Shedirpharma', ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_articles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455a6610",
   "metadata": {},
   "source": [
    "# Using the TfIDFVectorizer\n",
    "\n",
    "Let's create a TfidfVectorizer object and call its fit_transform method on our corpus. By fitting the vectorizer, it computes the TF-IDF score of each token with respect to every article.\n",
    "\n",
    "As result, the corpus_vectorized variable is a scipy sparse matrix containing 10k rows (one row for each article) and ~110k columns (one column for each token found in the corpus)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f6507f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 121820)\n"
     ]
    }
   ],
   "source": [
    "# apply the TfidfVectorizer to corpus\n",
    "vectorizer = TfidfVectorizer()\n",
    "corpus = df_articles['text']\n",
    "\n",
    "corpus_vectorized = vectorizer.fit_transform(corpus)\n",
    "print(corpus_vectorized.shape) #(10000, 121820)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04511e2",
   "metadata": {},
   "source": [
    "We can then reuse the vectorizer with the transform method to compute the TF-IDF values of the tokens in the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378c1abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 121820)\n"
     ]
    }
   ],
   "source": [
    "# vectorize the query\n",
    "\n",
    "query = 'learn data science'\n",
    "\n",
    "query_vectorized = vectorizer.transform([query])\n",
    "print(query_vectorized.shape) #(1, 121820)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8ffe89",
   "metadata": {},
   "source": [
    "Now, both the query and each article have been mapped to vectors of TF-IDF scores with the same dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b780d1",
   "metadata": {},
   "source": [
    "# Compute Similarities between Queries and Articles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f47969",
   "metadata": {},
   "source": [
    "Next, we compute the similarity between the query vector and each of the articles vectors by performing a matrix multiplication between query_vectorized and the transpose of corpus_vectorized, thus obtaining an array of 10k elements where each element is the score of an article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6deadaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# compute scores as the dot product between the query vector and the documents vectors\n",
    "scores = query_vectorized.dot(corpus_vectorized.transpose())\n",
    "scores_array = scores.toarray()[0]\n",
    "print(scores_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf80869",
   "metadata": {},
   "source": [
    "There are multiple similarity measures to choose from for computing the similarity between two vectors, such as \n",
    "1. Dot Product\n",
    "2. Cosine similarity\n",
    "3. Euclidean distance "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667a4000",
   "metadata": {},
   "source": [
    "# show Results\n",
    "\n",
    "Now we just have to find the indices of scores_array with the highest scores, find their corresponding articles in df_articles and show them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "185d6874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. (score: 0.6153) Top 8 free courses to learn data science\n",
      "2. (score: 0.5970) How to Transition to Data Science from Computer Science?\n",
      "3. (score: 0.5936) Is Data Science a science?\n",
      "4. (score: 0.5175) 5 Data Science Podcasts You Should be Listening To\n",
      "5. (score: 0.5016) Who is a Data Scientist?\n",
      "6. (score: 0.4875) Data Science for Business\n",
      "7. (score: 0.4592) Timeline for Data Science Competence\n",
      "8. (score: 0.4493) AI+ Subscription Content Available Right Now\n",
      "9. (score: 0.4487) Highly Effective Data Science Teams\n",
      "10. (score: 0.4453) A Layman’s Guide to Data Science: How to Become a (Good) Data Scientist\n"
     ]
    }
   ],
   "source": [
    "# retrieve the top_n articles with the highest scores and show them\n",
    "def show_best_results(df_articles, scores_array, top_n = 10):\n",
    "    sorted_indices = scores_array.argsort()[::-1]\n",
    "    for position, idx in enumerate(sorted_indices[:top_n]):\n",
    "        row = df_articles.iloc[idx]\n",
    "        title = row['title']\n",
    "        score = scores_array[idx]\n",
    "        print(f\"{position+1}. (score: {score:.4f}) {title}\")\n",
    "\n",
    "show_best_results(df_articles, scores_array, top_n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf92718",
   "metadata": {},
   "source": [
    "The results are okay, but let's try also with a query containing some stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8271053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. (score: 0.5943) What in the “Hello World” is Natural Language Processing (NLP)?\n",
      "2. (score: 0.3998) How to Transition to Data Science from Computer Science?\n",
      "3. (score: 0.3986) Top 8 free courses to learn data science\n",
      "4. (score: 0.3899) Is Data Science a science?\n",
      "5. (score: 0.3547) AI+ Subscription Content Available Right Now\n",
      "6. (score: 0.3325) Data Science for Business\n",
      "7. (score: 0.3271) 5 Data Science Podcasts You Should be Listening To\n",
      "8. (score: 0.3264) Who is a Data Scientist?\n",
      "9. (score: 0.3190) Timeline for Data Science Competence\n",
      "10. (score: 0.3022) A Layman’s Guide to Data Science: How to Become a (Good) Data Scientist\n"
     ]
    }
   ],
   "source": [
    "# try a different query\n",
    "\n",
    "query = 'how to learn data science with nlp'\n",
    "\n",
    "query_vectorized = vectorizer.transform([query])\n",
    "scores = query_vectorized.dot(corpus_vectorized.transpose())\n",
    "scores_array = scores.toarray()[0]\n",
    "show_best_results(df_articles, scores_array, top_n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbbc7b7",
   "metadata": {},
   "source": [
    "Still the results are impressive and related. Even without filtering stopwords, the tf-idf heuristic gives low importance to common words and high importance to rare words, thus producing a similar effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9222df8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpplanet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
